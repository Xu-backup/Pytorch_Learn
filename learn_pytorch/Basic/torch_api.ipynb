{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "包torch包含了多维张量的数据结构以及基于其上的多种数学操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(1,2,3,4,5)\n",
    "a.numel()\n",
    "torch.no_grad() #不计算梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"黑体\" color=white font size=5>创建操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.5000, 2.0000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 10\n",
    "torch.eye(num) #返回对角线为1的矩阵\n",
    "\n",
    "start = 1\n",
    "end = 0\n",
    "torch.linspace(start, end, steps=10, out=None) #间隔均匀的取steps个点产生一维张量\n",
    "torch.logspace(start, end, steps=10, out=None) #在10^start到10^end之间取steps个点\n",
    "\n",
    "\n",
    "size = [2,3]\n",
    "torch.rand(size)      #从0，1均匀分布中随机采样\n",
    "torch.randn(size)     ##从0均值，1方差中随机采样\n",
    "\n",
    "torch.arange(1,2.5,0.5)  #从1到2.5以0.5为步长的tensor序列 range类似，但是建议使用arange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"黑体\" color=white font size=5> 索引,切片,连接,换位操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对给定维度的张量序列进行连接操作,是chunk和split的反操作\n",
    "x = torch.randn(4,3)\n",
    "y = torch.cat([x,x,x],dim=0)\n",
    "y.shape\n",
    "\n",
    "#在dim维度上将input均匀分成chunks份\n",
    "torch.chunk(input=x, chunks=2, dim=0) \n",
    "\n",
    "##在dim上按照split_size进行划分，不能均分的话最后一个会小于其他块\n",
    "x = torch.rand([3,4,5])\n",
    "torch.split(x,2,dim=2)\n",
    "\n",
    "#沿给定轴dim，将输入索引张量index指定位置的值进行聚合。\n",
    "# out[i][j][k] = tensor[index[i][j][k]][j][k]  # dim=0\n",
    "# out[i][j][k] = tensor[i][index[i][j][k]][k]  # dim=1\n",
    "# out[i][j][k] = tensor[i][j][index[i][j][k]]  # dim=2\n",
    "#可以理解成将input的dim维度按照index进行重新排序\n",
    "t = torch.Tensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "torch.gather(input=t, dim=1, index=torch.LongTensor([[0,0],[1,0]]))\n",
    "\n",
    "##返回非零元素索引\n",
    "torch.nonzero(torch.Tensor([1, 1, 1, 0, 1]))\n",
    "\n",
    "#压缩去除形状中的1部分,可以指定维度\n",
    "x = torch.squeeze(torch.rand([1,1,10]),dim=1)\n",
    "x.shape\n",
    "#与squeeze相反\n",
    "torch.unsqueeze(x,dim=-1).shape\n",
    "\n",
    "#沿着一个新维度进行连接 3*[1,2] -> [3,1,2]\n",
    "x = torch.rand(1,2)\n",
    "torch.stack([x,x,x],dim=0).shape\n",
    "\n",
    "#交换dim0与dim1的维度\n",
    "x = torch.transpose(x,0,1)\n",
    "x.shape\n",
    "\n",
    "#返回一个新的原始tensor的视图\n",
    "x = torch.randn(3,4,5)\n",
    "x.permute((2,0,1)).size()\n",
    "\n",
    "#重塑形状，通常是一个视图\n",
    "torch.reshape(x, (10,-1)).size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"黑体\" color=white font size=5> 随机采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, -0.2185, -0.0511,  0.5179,  0.4653, -0.5264, -0.3094,  1.0748,\n",
       "         0.6943, -0.9734])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#输入每个位置为1的概率，输出采样结果\n",
    "a = torch.empty(3,3).uniform_(0,1)\n",
    "torch.bernoulli(a)\n",
    "\n",
    "#input为取到的概率,在多项式分布中采样任意个点,replacement表示是否可重复\n",
    "weights = torch.tensor([0, 10, 3, 0], dtype=torch.float) # create a tensor of weights\n",
    "torch.multinomial(weights, 4, replacement=True)\n",
    "\n",
    "#输入mean与std实现从正态分布中采样\n",
    "#可以选择形状\n",
    "torch.normal(0,1,size=[2,3])\n",
    "torch.normal(mean=0, std=torch.arange(0,1,0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"黑体\" color=white font size=5> 序列化(保存与读取)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存一个对象\n",
    "import torchvision\n",
    "import io\n",
    "torch.save()\n",
    "model_vgg = torchvision.models.vgg16()\n",
    "\n",
    "#保存模型\n",
    "torch.save(model_vgg.state_dict(),\"vgg16_method2.pth\") ##只有参数\n",
    "\n",
    "#加载模型\n",
    "model2_vgg = torchvision.models.vgg16()         \n",
    "model2_vgg.load_state_dict(torch.load(\"vgg16_method2.pth\"),strict=False)  ##再回复参数\n",
    "\n",
    "#保存数据\n",
    "x = torch.rand(1,2)\n",
    "buffer = io.BytesIO()\n",
    "torch.save(x, buffer)\n",
    "\n",
    "#读取一个对象,map_loaction可以对数据进行重映射\n",
    "torch.load(\"x.pt\",map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"黑体\" color=white font size=5> 数学操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "asin() missing 1 required positional arguments: \"input\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#按位操作\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#反正弦 arcsin\u001b[39;00m\n\u001b[0;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39matan() \u001b[38;5;66;03m#反正切 arctan\u001b[39;00m\n\u001b[0;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mceil() \u001b[38;5;66;03m#对每个元素向上取整\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: asin() missing 1 required positional arguments: \"input\""
     ]
    }
   ],
   "source": [
    "#按位操作\n",
    "torch.asin() #反正弦 arcsin\n",
    "torch.atan() #反正切 arctan\n",
    "torch.ceil() #对每个元素向上取整\n",
    "torch.clamp()  #将每个元素收缩到min,max区间，原本在区间的不变，大的变为max，小的变为min\n",
    "input = torch.rand([2,3])\n",
    "value = 2\n",
    "torch.div(input, value) #逐元素除法\n",
    "torch.mul(input,value) #逐元素乘法\n",
    "torch.reciprocal(input) #逐个元素取倒数\n",
    "torch.round(value) #逐元素舍入到最近的整数\n",
    "torch.sign(value) #返回一个元素的正负\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"黑体\" color=white font size=5> Reduction Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7188, -1.5850,  0.6654, -0.4265],\n",
      "        [-0.0067,  0.4627,  2.3477, -1.6450],\n",
      "        [-0.9745,  2.2250,  0.6201, -0.6038]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Reduciton Ops\n",
    "\n",
    "input = torch.randn([3,4])\n",
    "print(input)\n",
    "torch.argmax(input,dim=0)  #返回dim中最大值的索引\n",
    "torch.argmin(input,dim=0) #返回最小值索引\n",
    "torch.amax(input,dim=0)  #返回最大值 amin返回最小值\n",
    "input[1][1] = False\n",
    "torch.all(input,dim=1)  ##每个都是True返回True\n",
    "torch.any(input)  ## 任意一个是True返回True\n",
    "\n",
    "other = torch.randn([3,4])\n",
    "torch.dist(input, other, 1) #返回两个张量之间的p距离\n",
    "torch.mean(input)  ##返回均值\n",
    "torch.std(input) #返回标准差\n",
    "torch.var(input) #返回方差\n",
    "torch.norm(input,1) #返回张量的p范数\n",
    "torch.prod(input) #返回所有元素的积，或者给定维度上的乘积\n",
    "\n",
    "#Comparision Ops\n",
    "torch.eq(input, other)\n",
    "torch.isnan(input)\n",
    "torch.le(input, other) #小于等于\n",
    "torch.sort(input,dim=1) #排序\n",
    "\n",
    "\n",
    "# other Ops\n",
    "\n",
    "torch.diag(input,diagonal=0) #input为1D返回2D对角矩阵，2D则返回1D对角元素\n",
    "torch.trace(input)  ##计算迹\n",
    "\n",
    "#矩阵复制\n",
    "torch.clone(input)\n",
    "input.detach()\n",
    "\n",
    "#矩阵乘法\n",
    "torch.mm(input,other.T).size()\n",
    "torch.randn([10,3,4])\n",
    "torch.bmm(torch.randn([10,3,4]), torch.randn([10,4,5])).size() #批处理的矩阵乘法，第一维会被当做batchsize\n",
    "torch.diff(input) #计算相邻元素的差值\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
