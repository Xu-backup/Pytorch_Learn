{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 font face = \"黑体\"> nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##torch.nn中主要是需要的网络模型结构类\n",
    "##torch.nn.functional 主要是与类功能一致的方法\n",
    "import torchvision.transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "#nn.Module所有网络结构的基类\n",
    "nn.Module\n",
    "\n",
    "##nn.Squential 将一系列结构进行封装\n",
    "model = nn.Sequential(\n",
    "          nn.Conv2d(1,20,5),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(20,64,5),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "##或者\n",
    "# model = nn.Sequential(OrderedDict([\n",
    "#           ('conv1', nn.Conv2d(1,20,5)),\n",
    "#           ('relu1', nn.ReLU()),\n",
    "#           ('conv2', nn.Conv2d(20,64,5)),\n",
    "#           ('relu2', nn.ReLU())\n",
    "#         ])) \n",
    "\n",
    "##模型的方法\n",
    "\n",
    "model.add_module(\"conv\",nn.Conv2d(64,3,3))  #在模型最后加层数\n",
    "model.to(torch.device('cpu'))  #将模型部署\n",
    "model.eval() #将模型设置为评估模式\n",
    "model.train() #将模型设置为训练模式\n",
    "##返回模型组成\n",
    "for module in model.modules():\n",
    "    print(module)\n",
    "##返回一个所有参数的迭代器,通常用于优化器的参数\n",
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "#获取特定参数\n",
    "t = model.get_parameter(\"conv.weight\")\n",
    "print(t.size())\n",
    "\n",
    "##返回需要保存的状态，包括参数和缓冲区\n",
    "##返回的是一个字典 可以调用keys等字典方法\n",
    "#torch.save(model.state_dict(),'weight.pt')\n",
    "model.state_dict().keys()\n",
    "\n",
    "model.load_state_dict() #读取模型，state_date中的key必须一致，strict参数调整是否要求两模型严格一致\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 font face = \"黑体\"> 容器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequencial将一系列封装成一个\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ])) \n",
    "#ModelList\n",
    "#将子模型装到一个list中\n",
    "list = nn.ModuleList([nn.Linear(10,10) for i in range(3)])\n",
    "for i in list:\n",
    "    print(list.state_dict().keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 font face = \"黑体\"> 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 卷积层\n",
    "nn.Conv1d()\n",
    "nn.Conv2d()\n",
    "nn.ConvTranspose1d() #转置卷积\n",
    "nn.ConvTranspose2d()\n",
    "##......\n",
    "\n",
    "##池化层\n",
    "nn.MaxPool1d()\n",
    "nn.MaxPool2d()\n",
    "nn.AvgPool1d()\n",
    "nn.AvgPool2d()\n",
    "##......\n",
    "\n",
    "##线性激活函数\n",
    "nn.ReLU()\n",
    "nn.LeakyReLU()\n",
    "nn.Sigmoid()\n",
    "nn.GELU()\n",
    "nn.Tanh()\n",
    "nn.Softmax()\n",
    "#......\n",
    "\n",
    "##归一化层，为了解决梯度消失问题，通常在激活函数之前\n",
    "nn.BatchNorm1d()\n",
    "nn.BatchNorm2d()\n",
    "nn.LayerNorm()\n",
    "\n",
    "##RNN基本网络结构\n",
    "nn.RNNBase()\n",
    "nn.RNN()\n",
    "nn.LSTM()\n",
    "\n",
    "##Transform基本网络结构\n",
    "nn.Transformer()\n",
    "nn.TransformerEncoder()\n",
    "nn.TransformerEncoderLayer()\n",
    "nn.TransformerDecoder()\n",
    "nn.TransformerDecoderLayer()\n",
    "\n",
    "##线性层\n",
    "nn.Linear()\n",
    "nn.Bilinear()\n",
    "#......\n",
    "\n",
    "##Dropout层，用于防止过拟合\n",
    "nn.Dropout() #以概率p将输入元素置为0\n",
    "nn.Dropout1d() #随机将一个channel置为0\n",
    "\n",
    "##损失计算 LossFunction\n",
    "nn.MSELoss()\n",
    "nn.CrossEntropyLoss()\n",
    "nn.BCELoss()\n",
    "nn.SoftMarginLoss()\n",
    "\n",
    "##Spares Layer\n",
    "nn.Embedding() #词嵌入层\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
